<h1 align="center">CatÃ¡logo de LMs Open-Source</h1>

> RepositÃ³rio dedicado Ã  anÃ¡lise e documentaÃ§Ã£o de Modelos de Linguagem open-source, com receitas prÃ¡ticas para seu uso responsÃ¡vel.

---

## ğŸª¶ Modelos Leves  
> Modelos leves, otimizados para rodar localmente em dispositivos com recursos computacionais limitados.

| ğŸ¤– Nome do Modelo | ğŸ§® ParÃ¢metros | ğŸ“‹ Tarefas Comuns         | âœï¸ DescriÃ§Ã£o                                  | ğŸ”— Link                                     |
|-------------------|---------------|---------------------------|-----------------------------------------------|----------------------------------------------|
| Cerebras GPT      | 111M, 3B         | -                         | EficiÃªncia em termos de computaÃ§Ã£o.           | -                                            |
| DCLM              | 1B               | DeduÃ§Ã£o lÃ³gica            | RaciocÃ­nio de senso comum.                    | -                                            |
| Qwen2             | 500M, 1B, 7B     | -                         | EscalÃ¡vel e de baixo custo de hardware.       | -                                            |
| LLaMA 3.1         | 8B               | Multitarefa               | PotÃªncia, mas nÃ£o Ã© tÃ£o leve.                 | -                                            |
| LaMini GPT        | 775M, 2B         | Multilinguagem            | Acompanhamento de instruÃ§Ãµes.                 | -                                            |
| MiniCPM           | 1B, 4B           | -                         | Desempenho equilibrado.                       | -                                            |
| Mistral Nemo      | 12B              | Tarefas Complexas de NLP  | PotÃªncia, mas nÃ£o Ã© tÃ£o leve.                 | -                                            |
| OpenELM           | 270M, 3B         | Multitarefa               | EficiÃªncia energÃ©tica.                        | -                                            |
| Phi-3.5           | 4B               | Multilinguagem            | Longo comprimento de contexto.                | -                                            |
| Pythia            | 160M, 3B         | GeraÃ§Ã£o de CÃ³digo         | -                                             | -                                            |
| Raposa            | 1.6B             | Aplicativos mÃ³veis        | Velocidade otimizada para aplicativos mÃ³veis. | -                                            |
| TinyLama          | 1B               | Aplicativos mÃ³veis        | Eficiente para aplicativos mÃ³veis.            | -                                            |

---
## ğŸ‹ï¸â€â™‚ï¸ Modelos Robustos  
> Modelos grandes e avanÃ§ados, projetados para resolver problemas complexos com grande capacidade de generalizaÃ§Ã£o.

| ğŸ¤– Nome do Modelo | ğŸ§® ParÃ¢metros | ğŸ“‹ Tarefas Comuns         | âœï¸ DescriÃ§Ã£o                                  | ğŸ”— Link                                                             |
|----------------|--------------|-------------------------------|------------------------------------------------------------|---------------------------------------------------------|
| Alpaca         | -            | -                             | -                                                          | -                                                       |
| BERT           | -            | -                             | -                                                          | -                                                       |
| BLOOM          | -            | -                             | -                                                          | -                                                       |
| Falcon         | -            | -                             | -                                                          | -                                                       |
| GPT-NeoX       | -            | -                             | -                                                          | -                                                       |
| OPT            | -            | -                             | -                                                          | -                                                       |

---
## ğŸ‡§ğŸ‡· Modelos Brasileiros  
> Modelos desenvolvidos especificamente para a lÃ­ngua portuguesa, focando em aplicaÃ§Ãµes no Brasil.

| ğŸ¤– Nome do Modelo | ğŸ§® ParÃ¢metros | ğŸ“‹ Tarefas Comuns | âœï¸ DescriÃ§Ã£o                             | ğŸ”— Link |
|-------------------|--------------|------------------|---------------------------------------------|--------|
| SabiÃ¡-2           |  -           | -                | -                                           | -      |
|                   |              |                  |                                             |        |
|                   |              |                  |                                             |        |

---
## ğŸ¤ ContribuiÃ§Ã£o  
ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga os passos abaixo para colaborar:  

1. FaÃ§a um fork do repositÃ³rio;  
2. Modifique o que desejar e crie um pull request;  
3. Detalhe o pull request. Descreva suas alteraÃ§Ãµes.  

---
## ğŸ“œ LicenÃ§a  
Este projeto Ã© licenciado sob a [MIT License](LICENSE).
