# Llama 3

Fam√≠lia de modelos desenvolvidos pela Meta Inc., √© uma nova tecnologia de ponta, dispon√≠vel em diversos tamanhos com bilh√µes par√¢metros (pr√©-treinados ou ajustados para instru√ß√µes (instruction-tuned)).

Os modelos Llama 3 instruction-tuned tem fine-tuning e otimiza√ß√µes para casos de uso de di√°logo/chat, superando muitos dos modelos de chat de c√≥digo aberto dispon√≠veis em benchmarks comuns.

---
## üîç Caracter√≠sticas Principais

- **Desenvolvido por:** Meta AI
- **Arquitetura:** Baseada em Transformers, decoder-only.
- **Tokenizer**: Tiktoken
- **Janela de Contexto**: 8192 tokens
- **N√∫mero de par√¢metros**: 8B, 70B
- **Dados de treinamento**: 15T de token
- **Mecanismo de aten√ß√£o**: Grouped-query attention
- **N√∫mero de l√≠nguas suportadas**: 30 l√≠nguas
- **Caracter√≠sticas**
  - Modelos fine-tuned.
  - Aprendizado refor√ßado com feedback humano.

---
## üß™ Desempenho em Benchmarks

## **Compara√ß√£o com outros modelos**
![Benchmark](./misc/llama3_benchmark.png)
Fonte: [https://ai.meta.com/blog/meta-llama-3/](https://ai.meta.com/blog/meta-llama-3/)



---
## üì• Vers√µes

O Llama 3 atualmente est√° dispon√≠vel em 3 vers√µes.

## **Llama 3.1**:
- Dispon√≠vel com tamanhos entre 8B e 405B.
- Pre-treinado com 15T de tokens.

## **Llama 3.2**:
- Multil√≠ngue.
- Instruction-tuned.
- Dispon√≠vel com tamanhos entre 1B e 3B.
- (text in/text out)

## **Llama 3.2 Vision**:
- Dispon√≠vel com tamanhos entre 11B e 90B.
- (text in + images in/text out)

## **Llama 3.3**:
- Multil√≠ngue.
- Instruction-tuned.
- (text in/text out)
- Tamanho de 70B

---
## ‚úÖ Pr√≥s
- Ideal para tarefas (textuais) mais exigentes, como racioc√≠nio, codifica√ß√£o e testes de profici√™ncia.
- Ajustado para tarefas baseadas em instru√ß√µes.
- Otimizado para di√°logos e intera√ß√µes em chat.

---
## ‚ùå Contras
- Janela de contexto relativamente pequena (8k tokens).
- Incapaz ou limitado, no caso do LLama 3.2 Vision, para tarefas multimodais.
- Aborda relativamente poucas l√≠nguas (30).

## üöÄ Como Usar 


---
## üìú Fontes

https://ai.meta.com/blog/meta-llama-3/

https://huggingface.co/meta-llama

https://docs.llama-api.com/quickstart

https://www.datacamp.com/pt/tutorial/run-llama-3-locally

https://lightning.ai/fareedhassankhan12/studios/building-llama-3-from-scratch

https://datasciencedojo.com/blog/llama-model-debate/

