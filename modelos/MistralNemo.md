## Mistral Nemo 12B

SubstituiÃ§Ã£o direta do Mistral 7B
Projetado para aplicaÃ§Ãµes globais e multilÃ­ngues. Treinado para chamadas de funÃ§Ã£o, possui uma grande janela de contexto e se destaca particularmente em inglÃªs, francÃªs, alemÃ£o, espanhol, italiano, portuguÃªs, chinÃªs, japonÃªs, coreano, Ã¡rabe e hindi.

---
## ðŸ” CaracterÃ­sticas Principais

- **Desenvolvido por:** Mistral AI
- **Arquitetura** Modelo de transformers.
  - Camadas: 40
  - DimensÃ£o: 5.120
  - Head dim: 128
  - Hidden dim: 14.436
  - FunÃ§Ã£o de AtivaÃ§Ã£o: SwiGLU
  - NÃºmero de heads: 32
  - NÃºmero de kv-heads: 8 (GQA)
  - Tamanho do vocabulÃ¡rio: 2**17 ~= 128k

---
## ðŸ§ª Desempenho em Benchmarks

## **Geral**

| **Benchmark**              | **Resultado** |
|----------------------------|---------------|
| **HellaSwag (0-shot)**      | 83.5%         |
| **Winogrande (0-shot)**     | 76.8%         |
| **OpenBookQA (0-shot)**     | 60.6%         |
| **CommonSenseQA (0-shot)**  | 70.4%         |
| **TruthfulQA (0-shot)**     | 50.3%         |
| **MMLU (5-shot)**           | 68.0%         |
| **TriviaQA (5-shot)**       | 73.8%         |
| **NaturalQuestions (5-shot)**| 31.2%         |

## **MMLU**

| **Language**  | **Score** |
|---------------|-----------|
| French        | 62.3%     |
| German        | 62.7%     |
| Spanish       | 64.6%     |
| Italian       | 61.3%     |
| Portuguese    | 63.3%     |
| Russian       | 59.2%     |
| Chinese       | 59.0%     |
| Japanese      | 59.0%     |

---
## âœ… PrÃ³s
1. **Tokenizer**: Treinado com mais de 100 lÃ­nguas e com compressÃ£o eficiente.
2. **Tokenizer**: Grande janela de contexto (128k tokens). Lida com sequÃªncias longas, ideal para documentos complexos.

---
## âŒ Contras
1. **Linguagem tÃ³xica**: Foi treinado com dados que contÃ©m linguagem tÃ³xica. Pode retornar respostas tÃ³xicas especialmente se receber inputs do tipo.
2. **PrecisÃ£o**: Pode retornar respostas erradas, omitir informaÃ§Ãµes ou incluir texto irrelevante nas respostas.

---
## ðŸš€ Como Usar 
> Pelo mistral inference (recomendado).

### **InstalaÃ§Ã£o**
```bash
pip install mistral_inference
```

### **Download**
```python
from huggingface_hub import snapshot_download
from pathlib import Path

mistral_models_path = Path.home().joinpath('mistral_models', 'Nemo-v0.1')
mistral_models_path.mkdir(parents=True, exist_ok=True)

snapshot_download(repo_id="mistralai/Mistral-Nemo-Base-2407", allow_patterns=["params.json", "consolidated.safetensors", "tekken.json"], local_dir=mistral_models_path)
```

### **Demo**
```bash
mistral-demo $HOME/mistral_models/Nemo-v0.1
```

### **Finetuning**
[mistral-finetune](https://github.com/mistralai/mistral-finetune).

---
## ðŸ“œ Fontes
https://mistral.ai/news/mistral-nemo/

https://huggingface.co/nvidia/Mistral-NeMo-12B-Base

https://huggingface.co/mistralai/Mistral-Nemo-Base-2407
