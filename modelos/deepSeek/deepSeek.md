<div align="center">
  <img src="https://github.com/Agents4Good/LMGuide/blob/main/imagens/logoDeepSeek.svg" width="60%" alt="DeepSeek LLM" />
</div>

<div align="center">
  <a href="https://huggingface.co/deepseek-ai" target="_blank">
    <img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white" />
  </a>
</div>

<p align="center">
  <a href="https://arxiv.org/abs/2401.02954"><b>Paper - DeepSeek LLM</b></a><br>
  <a href="https://arxiv.org/abs/2501.12948"><b>Paper - DeepSeek R1</b></a>
</p>

---
## 1. Introdu√ß√£o

DeepSeek introduziu uma nova abordagem para melhorar as capacidades de racioc√≠nio de modelos de linguagem por meio de aprendizado por refor√ßo (RL), conforme detalhado em seu recente artigo sobre o DeepSeek-R1.

Esta pesquisa representa um avan√ßo significativo na forma como podemos aprimorar a capacidade de modelos para resolver problemas complexos usando apenas aprendizado por refor√ßo, sem depender fortemente de ajuste fino supervisionado.

DeepSeek-R1 √© o modelo de racioc√≠nio de primeira gera√ß√£o da DeepSeek, com desempenho compar√°vel ao OpenAI-o1. Ele est√° dispon√≠vel em v√°rias vers√µes, otimizadas para diferentes capacidades computacionais:

| Tamanho do Modelo | Descri√ß√£o                                                                 |
|-------------------|---------------------------------------------------------------------------|
| DeepSeek-R1 **1.5B**          | Vers√£o leve, otimizada para infer√™ncia r√°pida em dispositivos de borda.    |
| DeepSeek-R1 **7B**            | Modelo balanceado, adequado para tarefas gerais de racioc√≠nio.             |
| DeepSeek-R1 **8B**            | Maior precis√£o e melhor compreens√£o contextual.                           |
| DeepSeek-R1 **14B**           | Capacidades aprimoradas de racioc√≠nio e solu√ß√£o de problemas.              |
| DeepSeek-R1 **32B**           | An√°lise l√≥gica mais forte e sa√≠das detalhadas.                            |
| DeepSeek-R1 **70B**           | Vers√£o avan√ßada para aplica√ß√µes de IA de alto n√≠vel.                      |

**Aten√ß√£o!** 
> N√£o confunda DeepSeek-LLM com DeepSeek-R1.

DeepSeek-LLM √© um conceito geral, que refere-se √† fam√≠lia de modelos da DeepSeek como um todo.<br>
DeepSeek-R1 √© um modelo especializado, voltado para racioc√≠nio l√≥gico e resolu√ß√£o de problemas.

---
## 2. Arquitetura do Modelo

O DeepSeek-R1 n√£o √© um modelo √∫nico, mas uma fam√≠lia de modelos que inclui: **DeepSeek-R1-Zero** e **DeepSeek-R1**.

- **DeepSeek-R1-Zero**: Representa o experimento inicial da equipe com aprendizado por refor√ßo puro, sem qualquer ajuste fino supervisionado. Partindo de um modelo base, a equipe aplicou RL diretamente, permitindo que o modelo desenvolvesse capacidades de racioc√≠nio por tentativa e erro. Apesar de atingir resultados impressionantes (71% de acur√°cia no AIME 2024), enfrentou limita√ß√µes significativas em legibilidade e consist√™ncia de linguagem.

- **DeepSeek-R1**: Utiliza uma abordagem de treinamento mais sofisticada em m√∫ltiplas etapas. Em vez de RL puro, inicia com ajuste fino supervisionado em um pequeno conjunto de exemplos cuidadosamente selecionados (chamados de "dados de partida fria") antes de aplicar RL. Esta abordagem supera as limita√ß√µes do DeepSeek-R1-Zero, alcan√ßando melhor desempenho. 

---
## 3. Treinamento 

1. **Aprendizado por Refor√ßo**: Diferente de modelos tradicionais que dependem predominantemente de aprendizado supervisionado, o DeepSeek-R1 utiliza RL extensivamente. O treinamento emprega otimiza√ß√£o relativa de pol√≠ticas em grupo (GRPO), focando em recompensas de precis√£o e formato para aprimorar as capacidades de racioc√≠nio sem a necessidade de grandes volumes de dados rotulados.

2. **T√©cnicas de Destila√ß√£o**: Para democratizar o acesso a modelos de alto desempenho, a DeepSeek tamb√©m lan√ßou vers√µes destiladas do R1, variando de 1,5 bilh√£o a 70 bilh√µes de par√¢metros. Essas vers√µes utilizam arquiteturas como Qwen e Llama, demonstrando que racioc√≠nios complexos podem ser encapsulados em modelos menores e mais eficientes. O processo de destila√ß√£o envolve ajuste fino desses modelos menores com dados sint√©ticos de racioc√≠nio gerados pelo DeepSeek-R1 completo, preservando alto desempenho a um custo computacional reduzido.

- **DeepSeek-R1-Zero**:
  - Inicia com o modelo base
  - Aplica aprendizado por refor√ßo diretamente
  - Utiliza recompensas simples baseadas em precis√£o e formato

- **DeepSeek-R1**:
  1. Ajuste fino supervisionado inicial com milhares de exemplos de alta qualidade
  2. Aprendizado por refor√ßo focado em tarefas de racioc√≠nio
  3. Coleta de novos dados de treinamento por amostragem de rejei√ß√£o
  4. Aprendizado por refor√ßo final abrangendo todos os tipos de tarefas

---
## 4. Downloads

> "R1" indica que esses modelos s√£o vers√µes distiladas de arquiteturas maiores, como Qwen e Llama, voltadas para um prop√≥sito espec√≠fico.<br>
> O processo de distilla√ß√£o reduz o tamanho e a complexidade do modelo enquanto tenta manter um desempenho pr√≥ximo ao do modelo maior.<br>
> "LLM" refere-se a modelos maiores e mais gerais.<br>
> "Base" refere-se a modelos para tarefas gerais de NLP.<br>
> "Chat" refere-se a modelos ajustados para tarefas conversacionais.

### Huggingface
|         Model         |                                Download                                    |                  
|:---------------------:|--------------------------------------------------------------------------: |
| DeepSeek-R1-Distill-Qwen-1.5B	| ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)   |
| DeepSeek-R1-Distill-Qwen-7B   | ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B)     |
| DeepSeek-R1-Distill-Llama-8B	| ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)    |
| DeepSeek-R1-Distill-Llama-70B	| ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B)   |
| DeepSeek LLM 7B Base  | ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/deepseek-llm-7b-base)  |
| DeepSeek LLM 7B Chat  | ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat)  |
| DeepSeek LLM 67B Base | ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/deepseek-llm-67b-base) |
| DeepSeek LLM 67B Chat | ü§ó [HuggingFace](https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat) |

---
## 5. Benchmarks

> Consulte aqui: https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/README.md#3-evaluation-results

---
## 6. Compara√ß√£o com outros Modelos

Ao contr√°rio dos modelos fechados, o DeepSeek-R1 oferece visibilidade do seu processo de racioc√≠nio passo a passo, permitindo aos usu√°rios rastrear, verificar e refinar as conclus√µes geradas pela IA.

Al√©m disso, por ser open-source sob a licen√ßa MIT, o DeepSeek-R1 oferece diversas vantagens:
- **Personaliza√ß√£o sem Restri√ß√µes**: Desenvolvedores podem ajustar e modificar o modelo para casos de uso espec√≠ficos, sem limita√ß√µes de licenciamento.
- **Melhorias pela Comunidade**: Pesquisadores e especialistas podem contribuir com aprimoramentos.
- **Efici√™ncia de Custos**: √â uma alternativa ideal para empresas que buscam integrar IA sem custos recorrentes.

---
## 7. Requisitos de Sistema

| Vers√£o do Modelo | VRAM (GPU)      | RAM (CPU)     | Armazenamento |
|------------------|-----------------|---------------|---------------|
| DeepSeek-R1 **1.5B**            | 4GB+           | 8GB+          | 5GB           |
| DeepSeek-R1 **7B**              | 12GB+          | 16GB+         | 10GB          |
| DeepSeek-R1 **8B**              | 16GB+          | 32GB+         | 15GB          |
| DeepSeek-R1 **14B**             | 24GB+          | 64GB+         | 30GB          |
| DeepSeek-R1 **32B**             | 48GB+          | 128GB+        | 60GB          |
| DeepSeek-R1 **70B**             | 80GB+          | 256GB+        | 120GB         |

---
## 8. Executando o DeepSeek-R1 Localmente com Ollama

O Ollama facilita a execu√ß√£o do DeepSeek-R1 localmente em seu sistema, sem a necessidade de APIs baseadas na nuvem. Os requisitos do sistema variam dependendo do tamanho do modelo escolhido.

#### Instalar o Ollama
Se ainda n√£o tiver o Ollama instalado, use o seguinte comando para configur√°-lo em sua m√°quina:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### Baixar e Configurar o DeepSeek-R1
Ap√≥s instalar o Ollama, √© poss√≠vel baixar o modelo DeepSeek-R1:

```bash
ollama pull deepseek-r1:7b
```

> A vers√£o "7b" refere-se ao modelo de 7 bilh√µes de par√¢metros. Substitua por "1.5b", "8b", "14b", "32b", "70b" ou at√© mesmo "671b".

#### Executar o DeepSeek-R1 Localmente
Para iniciar uma sess√£o interativa com o modelo, execute:

```bash
ollama run deepseek-r1:7b
```

Este comando permite enviar prompts e receber respostas em tempo real.

---
## 9. Acesso via API DeepSeek

A DeepSeek oferece uma API compat√≠vel com o formato da OpenAI, permitindo integra√ß√£o em diversas aplica√ß√µes.

- a. **Obter uma Chave de API**: Acesse a plataforma de API da DeepSeek para criar uma conta e gerar sua chave de API exclusiva.
- b. Defina a `base_url` para `https://api.deepseek.com/v1`.
- c. Use sua chave de API para autentica√ß√£o, geralmente via Bearer Token no cabe√ßalho HTTP.
- d. Utilize a API para enviar prompts e receber respostas do DeepSeek-R1.
- e. DeepSeek API Docs: https://api-docs.deepseek.com/

```python
# Please install OpenAI SDK first: `pip3 install openai`

from openai import OpenAI

client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False
)

print(response.choices[0].message.content)
```

---
## 10. Aplica√ß√µes que usam o DeepSeek

> Em constru√ß√£o

---
## 11. Fontes

- [Artigo DeepSeek-R1](https://arxiv.org/abs/2501.12948)
- [Artigo DeepSeek-LLM](https://arxiv.org/abs/2401.02954)
- [Artigo Medium - PankaJ](https://medium.com/@pankaj_pandey/deepseek-r1-an-advanced-reasoning-model-for-ai-applications-using-ollama-0497a4899cb2)
- [Artigo Medium - Isaak Kamau](https://medium.com/@isaakmwangi2018/a-simple-guide-to-deepseek-r1-architecture-training-local-deployment-and-hardware-requirements-300c8799112)
- [Site Oficial](https://www.deepseek.com/)
- [HuggingFace](https://huggingface.co/deepseek-ai)
