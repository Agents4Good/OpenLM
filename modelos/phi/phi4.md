<div align="center">
  <a href="https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4" target="_blank">
    <img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white" />
  </a>
</div>

<p align="center">
  <a href="https://arxiv.org/abs/2412.08905"><b>üìú Paper - Phi 4</b></a>
</p>

---
## 1. Introdu√ß√£o

Phi-4, √© o mais recente modelo de linguagem pequeno da fam√≠lia Phi, que oferece resultados de alta qualidade em um tamanho compacto (14 bilh√µes de par√¢metros).

Este modelo se destaca em racioc√≠nio complexo em √°reas como matem√°tica, al√©m do processamento de linguagem convencional.

---
## 2. Compara√ß√£o com outros modelos

Diferentemente da maioria dos modelos de linguagem, que se baseiam principalmente em fontes de dados org√¢nicas, como conte√∫do da web ou c√≥digo, o phi-4 incorpora estrategicamente dados sint√©ticos ao longo de todo o processo de treinamento.

Enquanto os modelos anteriores da fam√≠lia Phi se concentravam em distilar as capacidades de um modelo professor (especificamente o GPT-4), o phi-4 supera substancialmente seu modelo professor em capacidades de perguntas e respostas focadas em STEM, evidenciando que as t√©cnicas de gera√ß√£o de dados e p√≥s-treinamento v√£o al√©m da distila√ß√£o.

Apesar de mudan√ßas m√≠nimas na arquitetura em rela√ß√£o ao phi-3, o phi-4 alcan√ßa um desempenho robusto em rela√ß√£o ao seu tamanho, especialmente em benchmarks focados em racioc√≠nio, devido a melhorias nos dados, curr√≠culo de treinamento e inova√ß√µes no esquema de p√≥s-treinamento.

---
## 3. Desenvolvimento do Phi-4

1. **Dados Sint√©ticos para Pr√©-treinamento e Treinamento Intermedi√°rio**:
    - Conjuntos de dados sint√©ticos de alta qualidade s√£o projetados para priorizar racioc√≠nio e resolu√ß√£o de problemas.
2. **Curadoria e Filtragem de Dados Org√¢nicos de Alta Qualidade**:
    - Fontes org√¢nicas, como conte√∫do da web, livros licenciados e reposit√≥rios de c√≥digo, s√£o cuidadosamente filtradas para gerar sementes de dados sint√©ticos focadas em racioc√≠nio profundo e valor educacional.
3. **P√≥s-Treinamento**:
    -  receita de p√≥s-treinamento foi aprimorada no phi-4 por meio da cria√ß√£o de novas vers√µes refinadas de conjuntos de dados SFT.

---
## 4. Benchmarks

![image](https://github.com/user-attachments/assets/75d254b0-c986-4c83-90af-5938cff98017)

Confira detalhes em: [Introducing Phi-4: Microsoft‚Äôs Newest Small Language Model Specializing in Complex Reasoning](https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090)

---
## 5. Download

|         Model         |                                Download                                    |                  
|:---------------------:|--------------------------------------------------------------------------: |
| Phi-4                 | [ü§ó HuggingFace](https://huggingface.co/microsoft/phi-4)                   |

---
## 6. Requisitos de Sistema

| Requisito                 | Detalhes                                                       |
|---------------------------|---------------------------------------------------------------|
| **Mem√≥ria RAM**            | M√≠nimo de 14 GB de RAM                                         |
| **Mem√≥ria VRAM**           | Placa gr√°fica com VRAM recomendada, mas n√£o essencial         |
| **Processador (CPU)**      | Processador moderno e de alto desempenho                       |
| **Armazenamento**          | Espa√ßo suficiente em disco para o modelo e dados associados (recomenda-se 50gb) |
| **Sistema Operacional**   | Compat√≠vel com Linux, macOS ou Windows                        |
| **Python**                 | Python 3.8 ou superior                                         |
| **PyTorch**                | Para opera√ß√µes de aprendizado de m√°quina                      |
| **Transformers (Hugging Face)** | Para carregar e interagir com o modelo                   |

---
## 7. Executar com o LM Studio

1. **Baixe o LM Studio**: https://lmstudio.ai/download
2. **Baixe o Modelo**: Execute via terminal o c√≥digo abaixo.
  ```bash
    lms get phi-4
  ```
3. **C√≥digo Python**:
  ```python
    # Example: reuse your existing OpenAI client code
    # Change the baseUrl to point to LM Studio
    from openai import OpenAI

    # Point to the local server
    client = OpenAI(base_url="http://localhost:1234/v1",
                    api_key="lm-studio")

    completion = client.chat.completions.create(
      model="phi-4",
      messages=[
        {"role": "system", "content": "Always answer in rhymes."},
        {"role": "user", "content": "Introduce yourself."}
      ],
      temperature=0.7,
    )

    print(completion.choices[0].message)
  ```

---
## 8. Fontes

- [Artigo Oficial](https://arxiv.org/abs/2412.08905)
- [Blog Microsoft](https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090)
- [Artigo Medium](https://ritvik19.medium.com/papers-explained-278-phi-4-ea59220f3f88)
